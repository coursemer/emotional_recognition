import cv2
import numpy as np
import os
import time
import requests
from datetime import datetime
from pathlib import Path
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from flask import Flask, render_template, Response, jsonify
from flask_cors import CORS
import threading

app = Flask(__name__)
CORS(app)

# --- Configuration ---
MODEL_URL = 'https://github.com/oarriaga/face_classification/raw/master/trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'
CASCADE_URL = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'

MODEL_FILE = 'fer2013_mini_XCEPTION.102-0.66.hdf5'
FACE_DETECTOR_PATH = 'haarcascade_frontalface_default.xml'
EMOTIONS = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']
WEBCAM_INDEX = 0

# Global variables
camera = None
classifier = None
face_detector = None
current_emotion = "neutral"
current_confidence = 0.0
current_probabilities = {emotion: 0.0 for emotion in EMOTIONS}

# Temporal smoothing for better accuracy
prediction_history = []
HISTORY_SIZE = 5  # Nombre de pr√©dictions √† moyenner
CONFIDENCE_THRESHOLD = 0.4  # Seuil minimum de confiance (40%)

def log_message(message):
    """Affiche un message de log avec un timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}")

def download_file(url, filename):
    """T√©l√©charge un fichier depuis une URL et le sauvegarde localement"""
    try:
        log_message(f"T√©l√©chargement de {filename}...")
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        os.makedirs(os.path.dirname(filename) or '.', exist_ok=True)
        
        total_size = int(response.headers.get('content-length', 0))
        block_size = 1024
        
        with open(filename, 'wb') as f:
            downloaded_size = 0
            for data in response.iter_content(block_size):
                f.write(data)
                downloaded_size += len(data)
        
        log_message(f"{filename} t√©l√©charg√© avec succ√®s")
        return True
    except Exception as e:
        log_message(f"Erreur lors du t√©l√©chargement de {filename}: {e}")
        return False

def check_and_download_files():
    """V√©rifie et t√©l√©charge les fichiers n√©cessaires s'ils ne sont pas pr√©sents"""
    files_to_download = [
        (MODEL_URL, MODEL_FILE),
        (CASCADE_URL, FACE_DETECTOR_PATH)
    ]
    
    all_files_available = True
    
    for url, filename in files_to_download:
        if not os.path.exists(filename):
            log_message(f"Fichier manquant: {filename}")
            if not download_file(url, filename):
                all_files_available = False
    
    return all_files_available

def initialize_models():
    """Initialise le mod√®le et le d√©tecteur de visage"""
    global classifier, face_detector
    
    log_message("V√©rification des fichiers n√©cessaires...")
    if not check_and_download_files():
        log_message("Erreur: Impossible de t√©l√©charger tous les fichiers n√©cessaires.")
        return False
    
    log_message("Chargement du mod√®le et du d√©tecteur de visage...")
    try:
        log_message(f"Chargement du mod√®le depuis : {MODEL_FILE}")
        classifier = load_model(MODEL_FILE)
        log_message("Mod√®le charg√© avec succ√®s")
        
        log_message(f"Chargement du classificateur de visage depuis : {FACE_DETECTOR_PATH}")
        face_detector = cv2.CascadeClassifier(FACE_DETECTOR_PATH)
        log_message("D√©tecteur de visage charg√© avec succ√®s")
        return True
    except Exception as e:
        log_message(f"ERREUR lors du chargement des fichiers: {e}")
        return False

def initialize_camera():
    """Initialise la webcam"""
    global camera
    
    log_message(f"Initialisation de la webcam (index: {WEBCAM_INDEX})...")
    camera = cv2.VideoCapture(WEBCAM_INDEX)
    
    if not camera.isOpened():
        log_message(f"ERREUR: Impossible d'ouvrir la webcam √† l'index {WEBCAM_INDEX}")
        return False
    
    log_message("Webcam initialis√©e avec succ√®s")
    return True

def generate_frames():
    """G√©n√®re les frames pour le streaming vid√©o avec optimisations FPS et pr√©cision am√©lior√©e"""
    global camera, classifier, face_detector, current_emotion, current_confidence, current_probabilities, prediction_history
    
    frame_count = 0
    last_faces = []
    
    while True:
        if camera is None or not camera.isOpened():
            break
            
        ret, frame = camera.read()
        if not ret:
            break
        
        frame_count += 1
        
        # Flip horizontalement pour effet miroir
        frame = cv2.flip(frame, 1)
        
        # Convertir en niveaux de gris
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # D√©tection des visages seulement toutes les 3 frames pour am√©liorer FPS
        if frame_count % 3 == 0:
            faces = face_detector.detectMultiScale(
                gray_frame,
                scaleFactor=1.2,  # Augment√© pour plus de vitesse
                minNeighbors=4,   # R√©duit pour plus de vitesse
                minSize=(80, 80), # Augment√© pour ignorer petits visages
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            # Filtrage simplifi√© des visages
            if len(faces) > 0:
                # Trier par taille et garder les 2 plus grands
                faces = sorted(faces, key=lambda f: f[2] * f[3], reverse=True)[:2]
                last_faces = faces
        else:
            # R√©utiliser les visages de la frame pr√©c√©dente
            faces = last_faces
        
        # Couleur rose girly
        pink_color = (255, 105, 180)
        
        # Traitement de chaque visage - pr√©diction seulement toutes les 2 frames
        for (x, y, w, h) in faces:
            # Dessiner le rectangle
            cv2.rectangle(frame, (x, y), (x+w, y+h), pink_color, 3)
            
            # Pr√©diction d'√©motion seulement toutes les 2 frames
            if frame_count % 2 == 0:
                roi_gray = gray_frame[y:y+h, x:x+w]
                
                try:
                    # Pr√©traitement am√©lior√© pour meilleure pr√©cision
                    roi_gray = cv2.resize(roi_gray, (64, 64))
                    
                    # √âgalisation d'histogramme pour am√©liorer le contraste
                    roi_gray = cv2.equalizeHist(roi_gray)
                    
                    # Normalisation
                    roi = roi_gray.astype('float') / 255.0
                    roi = img_to_array(roi)
                    roi = np.expand_dims(roi, axis=0)
                    
                    # Pr√©diction
                    prediction = classifier.predict(roi, verbose=0)[0]
                    
                    # Ajouter √† l'historique pour lissage temporel
                    prediction_history.append(prediction)
                    if len(prediction_history) > HISTORY_SIZE:
                        prediction_history.pop(0)
                    
                    # Moyenner les pr√©dictions sur l'historique
                    if len(prediction_history) >= 3:  # Au moins 3 pr√©dictions
                        smoothed_prediction = np.mean(prediction_history, axis=0)
                    else:
                        smoothed_prediction = prediction
                    
                    emotion_probability = np.max(smoothed_prediction)
                    emotion_label = EMOTIONS[smoothed_prediction.argmax()]
                    
                    # Appliquer seuil de confiance
                    if emotion_probability >= CONFIDENCE_THRESHOLD:
                        # Mettre √† jour les variables globales seulement si confiance suffisante
                        current_emotion = emotion_label
                        current_confidence = emotion_probability * 100
                        
                        # Stocker toutes les probabilit√©s pour comparaison
                        for i, emotion in enumerate(EMOTIONS):
                            current_probabilities[emotion] = float(smoothed_prediction[i] * 100)
                    # Sinon, garder l'√©motion pr√©c√©dente
                    
                except Exception as e:
                    pass  # Ignorer les erreurs silencieusement pour ne pas ralentir
            
            # Afficher le texte avec l'√©motion actuelle
            text = f"{current_emotion}: {current_confidence:.1f}%"
            cv2.putText(frame, text, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, pink_color, 2)
        
        # Encoder le frame en JPEG avec qualit√© r√©duite pour plus de vitesse
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 75]  # Qualit√© 75 au lieu de 95 par d√©faut
        ret, buffer = cv2.imencode('.jpg', frame, encode_param)
        frame = buffer.tobytes()
        
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/')
def index():
    """Page d'accueil"""
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """Route pour le streaming vid√©o"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/emotion')
def get_emotion():
    """API pour obtenir l'√©motion actuelle et toutes les probabilit√©s"""
    return jsonify({
        'emotion': current_emotion,
        'confidence': round(current_confidence, 1),
        'probabilities': {k: round(v, 1) for k, v in current_probabilities.items()}
    })

@app.route('/health')
def health():
    """V√©rification de l'√©tat de l'application"""
    return jsonify({
        'status': 'ok',
        'camera': camera is not None and camera.isOpened(),
        'model': classifier is not None
    })

if __name__ == '__main__':
    log_message("üéÄ D√©marrage de l'application Flask de reconnaissance d'√©motions üéÄ")
    
    # Initialiser les mod√®les
    if not initialize_models():
        log_message("Impossible d'initialiser les mod√®les. Arr√™t.")
        exit(1)
    
    # Initialiser la cam√©ra
    if not initialize_camera():
        log_message("Impossible d'initialiser la cam√©ra. Arr√™t.")
        exit(1)
    
    log_message("‚ú® Application pr√™te! Ouvrez http://localhost:5000 dans votre navigateur ‚ú®")
    
    try:
        app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)
    finally:
        if camera is not None:
            camera.release()
        log_message("Application arr√™t√©e")
